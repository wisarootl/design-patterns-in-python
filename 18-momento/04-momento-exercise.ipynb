{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memento Coding Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TokenMachine` is in charge of keeping tokens. Each `Token` is a reference type with a single numerical value. The machine supports adding tokens and, when it does, it returns a memento representing the state of that system at that given time.\n",
    "\n",
    "You are asked to fill in the gaps and implement the Memento design pattern for this scenario. Pay close attention to the situation where a token is fed in as a reference and its value is subsequently changed on that reference - you still need to return the correct system snapshot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import TestCase, main\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, value=0):\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "class Memento(list):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TokenMachine:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "\n",
    "    def add_token_value(self, value):\n",
    "        return self.add_token(Token(value))\n",
    "\n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token)\n",
    "        return Memento(deepcopy(self.tokens))\n",
    "\n",
    "    def revert(self, memento):\n",
    "        self.tokens = [Token(x.value) for x in memento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TokenMachine()\n",
    "m = tm.add_token_value(123)\n",
    "tm.add_token_value(456)\n",
    "tm.revert(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_fiddled_token (__main__.Evaluate) ... ok\n",
      "test_single_token (__main__.Evaluate) ... ok\n",
      "test_two_tokens (__main__.Evaluate) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made a token with value 111 and kept a reference\n",
      "Added this token to the list\n",
      "Added token 222 and kept a memento\n",
      "Changed 111 token's value to 333... pay attention!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1ee05e37190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Evaluate(TestCase):\n",
    "    def test_single_token(self):\n",
    "        tm = TokenMachine()\n",
    "        m = tm.add_token_value(123)\n",
    "        tm.add_token_value(456)\n",
    "        tm.revert(m)\n",
    "        self.assertEqual(1, len(tm.tokens),\n",
    "                         msg='We expect exactly 1 token')\n",
    "        self.assertEqual(123, tm.tokens[0].value,\n",
    "                         msg='The first token\\'s value should be 123')\n",
    "\n",
    "    def test_two_tokens(self):\n",
    "        tm = TokenMachine()\n",
    "        tm.add_token_value(1)\n",
    "        m = tm.add_token_value(2)\n",
    "        tm.add_token_value(3)\n",
    "        tm.revert(m)\n",
    "        self.assertEqual(2, len(tm.tokens), msg='We should have exactly 2 tokens')\n",
    "        self.assertEqual(1, tm.tokens[0].value,\n",
    "                         msg='First token should have value 1, you got ' + str(tm.tokens[0].value))\n",
    "        self.assertEqual(2, tm.tokens[1].value, msg='Second token should have the value 2')\n",
    "\n",
    "    # this one is deliberately tricky\n",
    "    def test_fiddled_token(self):\n",
    "        tm = TokenMachine()\n",
    "\n",
    "        token = Token(111)\n",
    "        print('Made a token with value 111 and kept a reference')\n",
    "\n",
    "        tm.add_token(token)\n",
    "        print('Added this token to the list')\n",
    "\n",
    "        m = tm.add_token_value(222)\n",
    "        print('Added token 222 and kept a memento')\n",
    "\n",
    "        print('Changed 111 token\\'s value to 333... pay attention!')\n",
    "        token.value = 333\n",
    "\n",
    "        tm.revert(m)\n",
    "\n",
    "        self.assertEqual(2, len(tm.tokens),\n",
    "                         'At this point, token machine should have exactly 2 tokens, you have ' + str(len(tm.tokens)))\n",
    "\n",
    "        self.assertEqual(111, tm.tokens[0].value,\n",
    "                         'You got the tokens[0] value wrong here. Hint: did you init the memento by value?')\n",
    "\n",
    "main(argv=['ignored', '-v'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20ac7aad763b689ebdaff2f53a3073c7ed55a0f51860968fbf5603f714378c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
